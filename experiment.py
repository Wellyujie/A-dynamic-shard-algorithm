import os
import csv
import time
import numpy as np
from config import Config
from data_generator import DataGenerator
from random_sharding import RandomSharding
from static_clustering import StaticClusteringSharding
from dynamic_sharding import DynamicSharding

# å®éªŒç»“æœä¿å­˜è·¯å¾„ï¼ˆè‡ªåŠ¨åˆ›å»ºæ–‡ä»¶å¤¹ï¼‰
RESULT_DIR = Config.PLOT_SAVE_PATH
os.makedirs(RESULT_DIR, exist_ok=True)
RESULT_CSV = os.path.join(RESULT_DIR, "experiment_results.csv")

# è¦å¯¹æ¯”çš„ç®—æ³•åˆ—è¡¨ï¼ˆè¦†ç›–ä½ è®ºæ–‡4.4èŠ‚æ‰€æœ‰å¯¹æ¯”éœ€æ±‚ï¼‰
ALGORITHMS = [
    {"name": "éšæœºåˆ†ç‰‡", "type": "random"},
    {"name": "é™æ€èšç±»åˆ†ç‰‡", "type": "static_clustering"},
    {"name": "åŠ¨æ€åˆ†ç‰‡ï¼ˆSAæ±‚è§£ï¼‰", "type": "dynamic_sa"},
    {"name": "åŠ¨æ€åˆ†ç‰‡ï¼ˆè´ªå©ªæ±‚è§£ï¼‰", "type": "dynamic_greedy"}
]

def run_single_experiment(num_nodes, num_shards, seed, initial_shard_type="random"):
    """
    è¿è¡Œå•æ¬¡å®éªŒï¼ˆä¸€ç»„è§„æ¨¡+ä¸€ä¸ªéšæœºç§å­ï¼‰
    :param num_nodes: èŠ‚ç‚¹æ•°
    :param num_shards: åˆ†ç‰‡æ•°
    :param seed: éšæœºç§å­ï¼ˆä¿è¯å¯å¤ç°ï¼‰
    :param initial_shard_type: ç»Ÿä¸€åˆå§‹åˆ†ç‰‡ç±»å‹ï¼ˆæ‰€æœ‰åŠ¨æ€ç®—æ³•ç”¨åŒä¸€ä¸ªåˆå§‹åˆ†ç‰‡ï¼‰
    :return: å•æ¬¡å®éªŒçš„æ‰€æœ‰ç®—æ³•ç»“æœï¼ˆåˆ—è¡¨ï¼‰
    """
    # 1. ç”Ÿæˆç»Ÿä¸€çš„å®éªŒæ•°æ®ï¼ˆæ‰€æœ‰ç®—æ³•ç”¨åŒä¸€ç»„æ•°æ®ï¼‰
    np.random.seed(seed)
    generator = DataGenerator(num_nodes=num_nodes)
    data = generator.get_data()

    # 2. ç”Ÿæˆç»Ÿä¸€çš„åˆå§‹åˆ†ç‰‡ï¼ˆæ‰€æœ‰åŠ¨æ€ç®—æ³•åŸºäºæ­¤ä¼˜åŒ–ï¼Œä¿è¯å¯¹æ¯”å…¬å¹³ï¼‰
    initial_sharding = None
    if initial_shard_type == "random":
        initial_sharding = RandomSharding(data=data, num_shards=num_shards)
    elif initial_shard_type == "clustering":
        initial_sharding = StaticClusteringSharding(data=data, num_shards=num_shards)
    else:
        raise ValueError("initial_shard_type must be 'random' or 'clustering'")

    initial_sharding.sharding()
    # ä¿å­˜åˆå§‹åˆ†ç‰‡ç»“æœï¼ˆä¾›åŠ¨æ€ç®—æ³•å¤ç”¨ï¼‰
    initial_shards = {k: list(v) for k, v in initial_sharding.shards.items()}

    experiment_results = []
    start_time_total = time.time()

    # 3. é€ä¸ªè¿è¡Œæ‰€æœ‰ç®—æ³•
    for algo in ALGORITHMS:
        algo_name = algo["name"]
        algo_type = algo["type"]
        print(f"\n=== è¿è¡Œå®éªŒï¼š{num_nodes}èŠ‚ç‚¹Ã—{num_shards}åˆ†ç‰‡Ã—ç§å­{seed} â†’ {algo_name} ===")

        # åˆå§‹åŒ–ç®—æ³•å®ä¾‹
        sharding_algo = None
        run_time = None
        iterations = 0

        if algo_type == "random":
            # éšæœºåˆ†ç‰‡ï¼ˆåŸºå‡†ï¼‰
            sharding_algo = RandomSharding(data=data, num_shards=num_shards)
            start_time = time.time()
            sharding_algo.sharding()
            run_time = time.time() - start_time
            iterations = 0  # éšæœºåˆ†ç‰‡æ— è¿­ä»£

        elif algo_type == "static_clustering":
            # é™æ€èšç±»åˆ†ç‰‡ï¼ˆåŸºå‡†ï¼‰
            sharding_algo = StaticClusteringSharding(data=data, num_shards=num_shards)
            start_time = time.time()
            sharding_algo.sharding()
            run_time = time.time() - start_time
            iterations = 0  # é™æ€èšç±»æ— è¿­ä»£

        elif algo_type == "dynamic_sa":
            # åŠ¨æ€åˆ†ç‰‡ï¼ˆSAæ±‚è§£å™¨ï¼‰- å¤ç”¨ç»Ÿä¸€åˆå§‹åˆ†ç‰‡ï¼ˆä¿®æ­£ç‰ˆï¼‰
            sharding_algo = DynamicSharding(
                data=data, num_shards=num_shards,
                init_sharding_type=initial_shard_type, seed=seed
            )
            # å¼ºåˆ¶è®¾ç½®ç»Ÿä¸€åˆå§‹åˆ†ç‰‡ï¼ˆé¿å… DynamicSharding.sharding() è¦†ç›–ï¼‰
            sharding_algo.shards = {k: list(v) for k, v in initial_shards.items()}
            sharding_algo._update_shard_mapping()
            sharding_algo.reset_metrics_cache()

            # ç›´æ¥æ„é€ å¹¶è°ƒç”¨ SASolverï¼ˆä¸è¦å†è°ƒç”¨ sharding_algo.sharding()ï¼Œå› ä¸ºé‚£ä¼šé‡æ–°ç”Ÿæˆåˆå§‹åˆ†ç‰‡ï¼‰
            from sa_solver import SASolver
            sa_solver = SASolver(sharding_algorithm=sharding_algo, seed=seed)
            # ä½¿ç”¨æ±‚è§£å™¨è¿”å›çš„ total_timeï¼ˆå†…éƒ¨è®¡æ—¶ï¼‰ä½œä¸ºè¿è¡Œæ—¶é—´ï¼Œé¿å…ä¸¤æ¬¡è®¡æ—¶
            best_shards, total_iters, total_time_sa, final_utility_sa = sa_solver.solve(verbose=False)
            run_time = total_time_sa
            iterations = total_iters

            # æŠŠæœ€ä¼˜ç»“æœå†™å› sharding_algoï¼ˆæ–¹ä¾¿åç»­ç»Ÿä¸€æŒ‡æ ‡è¯»å–ï¼‰
            sharding_algo.shards = best_shards
            sharding_algo._update_shard_mapping()
            sharding_algo.reset_metrics_cache()

        elif algo_type == "dynamic_greedy":
            # åŠ¨æ€åˆ†ç‰‡ï¼ˆè´ªå©ªæ±‚è§£å™¨ï¼‰- å¤ç”¨ç»Ÿä¸€åˆå§‹åˆ†ç‰‡
            sharding_algo = DynamicSharding(
                data=data, num_shards=num_shards,
                init_sharding_type=initial_shard_type, seed=seed
            )
            # å¼ºåˆ¶è®¾ç½®ç»Ÿä¸€åˆå§‹åˆ†ç‰‡
            sharding_algo.shards = {k: list(v) for k, v in initial_shards.items()}
            sharding_algo._update_shard_mapping()
            sharding_algo.reset_metrics_cache()

            # æ›¿æ¢ä¸ºè´ªå©ªæ±‚è§£å™¨
            from greedy_solver import GreedySolver
            greedy_solver = GreedySolver(sharding_algorithm=sharding_algo)
            # è¿è¡Œä¼˜åŒ–ï¼ˆGreedySolver.solve å·²è¿”å› total_timeï¼‰
            final_shards, iter_num, total_time_greedy, _ = greedy_solver.solve(verbose=False)
            run_time = total_time_greedy
            iterations = iter_num

            # æ›´æ–°åˆ†ç‰‡ç»“æœ
            sharding_algo.shards = final_shards
            sharding_algo._update_shard_mapping()
            sharding_algo.reset_metrics_cache()

        else:
            raise ValueError(f"æœªçŸ¥ç®—æ³•ç±»å‹ï¼š{algo_type}")

        # 4. è®¡ç®—æ‰€æœ‰æ ¸å¿ƒæŒ‡æ ‡ï¼ˆç¡®ä¿ç¼“å­˜å·²åˆ·æ–°ï¼‰
        intra_rate = sharding_algo.calculate_intra_shard_rate()
        total_loss = sharding_algo.calculate_transmission_loss()
        cross_loss = sharding_algo.metrics_cache.get("transmission_loss_cross", 0.0)
        total_utility = sharding_algo.calculate_system_total_utility()
        gini_shard = sharding_algo.calculate_gini_coefficient(level="shard")
        gini_node = sharding_algo.calculate_gini_coefficient(level="node")

        # 5. ä¿å­˜å•æ¬¡ç®—æ³•ç»“æœ
        result = {
            "èŠ‚ç‚¹æ•°": num_nodes,
            "åˆ†ç‰‡æ•°": num_shards,
            "éšæœºç§å­": seed,
            "ç®—æ³•åç§°": algo_name,
            "ç‰‡å†…äº¤æ˜“ç‡": round(intra_rate, 6),
            "æ€»ä¼ è¾“æŸè€—": round(total_loss, 2),
            "è·¨ç‰‡ä¼ è¾“æŸè€—": round(cross_loss, 2),
            "ç³»ç»Ÿæ€»æ•ˆç”¨": round(total_utility, 6),
            "åˆ†ç‰‡åŸºå°¼ç³»æ•°": round(gini_shard, 6),
            "èŠ‚ç‚¹åŸºå°¼ç³»æ•°": round(gini_node, 6),
            "è¿è¡Œæ—¶é—´(ç§’)": round(run_time if run_time is not None else 0.0, 4),
            "è¿­ä»£æ¬¡æ•°": iterations
        }
        experiment_results.append(result)
        print(f"âœ… {algo_name} å®Œæˆï¼šæ•ˆç”¨={total_utility:.4f}ï¼Œè€—æ—¶={result['è¿è¡Œæ—¶é—´(ç§’)']:.2f}ç§’")

    total_time = time.time() - start_time_total
    print(f"\nğŸ“Š å•æ¬¡å®éªŒå®Œæˆï¼ˆ{num_nodes}èŠ‚ç‚¹Ã—{num_shards}åˆ†ç‰‡Ã—ç§å­{seed}ï¼‰ï¼Œæ€»è€—æ—¶ï¼š{total_time:.2f}ç§’")
    return experiment_results

def main():
    """
    ä¸»å®éªŒæµç¨‹ï¼šéå†æ‰€æœ‰è§„æ¨¡+é‡å¤æ¬¡æ•°ï¼Œæ‰¹é‡è¿è¡Œå®éªŒ
    """
    print("="*80)
    print("ğŸ¯ å¾®ç”µç½‘åŠ¨æ€åˆ†ç‰‡ç®—æ³•å¯¹æ¯”å®éªŒï¼ˆè®ºæ–‡4.4èŠ‚ï¼‰")
    print(f"å®éªŒè§„æ¨¡ç»„åˆï¼š{Config.SCALES}")
    print(f"æ¯ç§è§„æ¨¡é‡å¤æ¬¡æ•°ï¼š{Config.EXPERIMENT_TIMES}")
    print(f"å¯¹æ¯”ç®—æ³•ï¼š{[algo['name'] for algo in ALGORITHMS]}")
    print(f"ç»“æœä¿å­˜è·¯å¾„ï¼š{RESULT_CSV}")
    print("="*80)

    # åˆå§‹åŒ–CSVæ–‡ä»¶ï¼ˆå†™å…¥è¡¨å¤´ï¼‰
    fieldnames = [
        "èŠ‚ç‚¹æ•°", "åˆ†ç‰‡æ•°", "éšæœºç§å­", "ç®—æ³•åç§°",
        "ç‰‡å†…äº¤æ˜“ç‡", "æ€»ä¼ è¾“æŸè€—", "è·¨ç‰‡ä¼ è¾“æŸè€—",
        "ç³»ç»Ÿæ€»æ•ˆç”¨", "åˆ†ç‰‡åŸºå°¼ç³»æ•°", "èŠ‚ç‚¹åŸºå°¼ç³»æ•°",
        "è¿è¡Œæ—¶é—´(ç§’)", "è¿­ä»£æ¬¡æ•°"
    ]
    with open(RESULT_CSV, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()

    # éå†æ‰€æœ‰å®éªŒç»„åˆï¼ˆè§„æ¨¡Ã—é‡å¤æ¬¡æ•°ï¼‰
    total_experiments = len(Config.SCALES) * Config.EXPERIMENT_TIMES
    current_experiment = 0
    for (num_nodes, num_shards) in Config.SCALES:
        for seed_offset in range(Config.EXPERIMENT_TIMES):
            current_experiment += 1
            seed = Config.RANDOM_SEED + seed_offset  # ä¸åŒç§å­ä¿è¯éšæœºæ€§
            print(f"\n" + "="*80)
            print(f"ğŸ“Œ æ­£åœ¨è¿è¡Œå®éªŒ {current_experiment}/{total_experiments}ï¼š{num_nodes}èŠ‚ç‚¹Ã—{num_shards}åˆ†ç‰‡Ã—ç¬¬{seed_offset+1}æ¬¡é‡å¤")
            print("="*80)

            # è¿è¡Œå•æ¬¡å®éªŒï¼ˆç»Ÿä¸€åˆå§‹åˆ†ç‰‡ä¸ºéšæœºåˆ†ç‰‡ï¼Œä¿è¯å¯¹æ¯”å…¬å¹³ï¼‰
            single_results = run_single_experiment(
                num_nodes=num_nodes, num_shards=num_shards,
                seed=seed, initial_shard_type="random"
            )

            # å°†å•æ¬¡å®éªŒç»“æœå†™å…¥CSV
            with open(RESULT_CSV, "a", newline="", encoding="utf-8") as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writerows(single_results)

    print("\n" + "="*80)
    print("ğŸ‰ æ‰€æœ‰å®éªŒè¿è¡Œå®Œæˆï¼")
    print(f"ğŸ“ å®éªŒæ•°æ®å·²ä¿å­˜è‡³ï¼š{RESULT_CSV}")
    print("ğŸ‘‰ ä¸‹ä¸€æ­¥ï¼šè¿è¡Œ plot_results.py ç”Ÿæˆè®ºæ–‡æ‰€éœ€å›¾è¡¨ï¼ˆæ”¶æ•›æ›²çº¿ã€åˆ†ç»„æŸ±çŠ¶å›¾ç­‰ï¼‰")
    print("="*80)

if __name__ == "__main__":
    main()
